{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import helpers\n",
    "import pathlib\n",
    "import json\n",
    "import time\n",
    "\n",
    "from datetime import datetime, timezone\n",
    "from selenium.webdriver import Remote, ChromeOptions\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "now = datetime.now(timezone.utc)\n",
    "# today = now.strftime(\"%Y-%m-%d\")\n",
    "today = \"2024-02-13\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NBS_DIR = pathlib.Path().resolve().parent\n",
    "BASE_DIR = NBS_DIR\n",
    "DATASET_DIR = BASE_DIR / \"dataset\"\n",
    "TODAYS_DIR = DATASET_DIR /today\n",
    "POSTS_DIR = TODAYS_DIR / \"posts\"\n",
    "print(BASE_DIR, POSTS_DIR, POSTS_DIR.exists())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "POSTS_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = ChromeOptions()\n",
    "MAX_PAGES = 1\n",
    "today = \"2024-02-13\"\n",
    "\n",
    "# disable downloading images\n",
    "prefs = {\"profile.managed_default_content_settings.images\": 2}\n",
    "options.add_experimental_option(\"prefs\", prefs)\n",
    "\n",
    "now = datetime.now(timezone.utc)\n",
    "# today = now.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "url_pattern = \"https://news.ycombinator.com/front?day={day}&p={page}\"\n",
    "detail_pattern = \"https://news.ycombinator.com/item?id={item_id}\"\n",
    "sbr_connection = helpers.get_sbr_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_datas = []\n",
    "with Remote(sbr_connection, options=options) as driver:\n",
    "    for page in range(1, MAX_PAGES + 1):\n",
    "        url = url_pattern.format(day=today, page=page)\n",
    "        print(page, url)\n",
    "        driver.get(url) # HTTP GET\n",
    "        time.sleep(2)\n",
    "        html_source = driver.page_source\n",
    "        html_datas.append(html_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_post_data(tr):\n",
    "    id = tr.attrs.get('id')\n",
    "    next_tr = tr.find_next('tr')\n",
    "    score_span = next_tr.find(\"span\", class_=\"score\")\n",
    "    score = None\n",
    "    if score_span:\n",
    "        score = \"\".join([x for x in score_span.get_text() if x.isdigit()])\n",
    "    title_element = tr.find(\"span\", class_=\"titleline\")\n",
    "    text = title_element.get_text()\n",
    "    target_links = [x.get('href') for x in tr.find_all('a') if x.get('href').startswith(\"http\")]\n",
    "    target_link = target_links[0] if len(target_links) >= 1 else None\n",
    "    detail_link = detail_pattern.format(item_id = id)\n",
    "    return  {\n",
    "            \"id\": id,\n",
    "            \"text\": text,\n",
    "            'target_link': target_link,\n",
    "            \"score\": score,\n",
    "            \"thread_link\": detail_link\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_link(url=None, driver=None):\n",
    "    if url is None:\n",
    "        return \"\"\n",
    "    if not f\"{url}\".startswith(\"http\"):\n",
    "        return \"\"\n",
    "    if not driver:\n",
    "        return \"\"\n",
    "    driver.get(url)\n",
    "    return driver.page_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_json_data(data, path=None):\n",
    "    id = data.get('id')\n",
    "    json_data = json.dumps(data, indent=4)\n",
    "    if path:\n",
    "        path.write_text(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_and_save(data, key, driver=None, path=None):\n",
    "    if path is None:\n",
    "        return \n",
    "    try:\n",
    "        data = scrape_link(data.get(key), driver=driver)\n",
    "    except:\n",
    "        data = None\n",
    "    if data is not None:\n",
    "        path.write_text(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape_all = True\n",
    "save_thread_data = True\n",
    "scrape_thread_detail = False\n",
    "scrape_target = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "for html_source in html_datas:\n",
    "    soup = BeautifulSoup(html_source, 'html.parser')\n",
    "    rows = soup.find_all('tr', class_=\"athing\")\n",
    "    with Remote(sbr_connection, options=options) as driver:\n",
    "        for tr in rows:\n",
    "            id = tr.attrs.get('id')\n",
    "            post_dir = POSTS_DIR / f\"{id}\"\n",
    "            post_dir.mkdir(parents=True, exist_ok=True)\n",
    "            json_output_path = post_dir  / 'detail.json'\n",
    "            thread_output_path = post_dir / \"thread.html\"\n",
    "            target_output_path = post_dir / \"target.html\"\n",
    "            data = extract_post_data(tr)\n",
    "            if save_thread_data or scrape_all:\n",
    "                if not json_output_path.exists():\n",
    "                    save_json_data(data, path=json_output_path)\n",
    "            if scrape_thread_detail or scrape_all:\n",
    "                if not thread_output_path.exists():\n",
    "                    scrape_and_save(data, 'thread_link', driver=driver, path=thread_output_path)\n",
    "            if scrape_target or scrape_all:\n",
    "                if not target_output_path.exists():\n",
    "                    scrape_and_save(data, 'target_link', driver=driver, path=target_output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
