{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import requests\n",
    "import urllib.parse\n",
    "import json\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NBS_DIR = NBS_DIR = pathlib.Path().resolve().parent\n",
    "BASE_DIR = NBS_DIR\n",
    "DATASET_DIR = BASE_DIR / \"dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def url_encode(params):\n",
    "    return urllib.parse.urlencode(params, quote_via=urllib.parse.quote_plus)\n",
    "\n",
    "def get_url(search_term=\"Python programming\"):\n",
    "    params = {\n",
    "        'lang': 'en_us',\n",
    "        'media': 'podcast',\n",
    "        'entity': 'podcastEpisode',\n",
    "        'limit': 10,\n",
    "        'term': search_term\n",
    "    }\n",
    "    encoded_params = url_encode(params)\n",
    "    return f\"https://itunes.apple.com/search?{encoded_params}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = get_url(search_term=\"systemd\")\n",
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "r = requests.get(url, headers={\"Content-Type\": \"application/json\"})\n",
    "\n",
    "data = r.json()\n",
    "\n",
    "results = data.get('results')\n",
    "\n",
    "results = sorted(results, key=lambda x: x['releaseDate'], reverse=True)\n",
    "\n",
    "for idx, result in enumerate(results):\n",
    "    kind = result.get('kind')\n",
    "    if kind != \"podcast-episode\":\n",
    "        continue\n",
    "    releaseDate = result.get('releaseDate')\n",
    "    podcastName = result['collectionName']\n",
    "    title = result['trackName']\n",
    "    episodeUrl = result['episodeUrl']\n",
    "    print(idx+1, title, podcastName, releaseDate, episodeUrl)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_openai_client():\n",
    "    return OpenAI(\n",
    "        base_url = 'http://localhost:11434/v1',\n",
    "        api_key='ollama', # required, but unused\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guess_language(content=\"\", client=None, raw=None):\n",
    "    if not isinstance(client, OpenAI):\n",
    "        client = get_openai_client()\n",
    "    system_prompt = \"\".join([\n",
    "        \"You are an expert at deciphering the type of language of text.\",\n",
    "    ])\n",
    "    prompt_start = \"\".join([\n",
    "        \"Respond only with your best guess of what the language is of the input text. Use real human languages.\",\n",
    "        \"Use the following:\"\n",
    "    ])\n",
    "    prompt_end=\"Using format of \\\"{'language': <generated-answer>}\\\" return a response with json\"\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": f\"{prompt_start} {content} {prompt_end}\",\n",
    "        }\n",
    "    ]\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"llama2\",\n",
    "        messages=messages,\n",
    "        response_format={ \"type\" : \"json_object\" }\n",
    "    )\n",
    "    if raw:\n",
    "        return response\n",
    "    try:\n",
    "        return json.loads(response.choices[0].message.content), True\n",
    "    except:\n",
    "        return response.choices[0].message.content, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, is_json = guess_language(\"Binärgewitter Talk #320: Für die Liebe zu systemd Binärgewitter \")\n",
    "if is_json:\n",
    "    print('language', pred.get('language'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = get_url(search_term=\"Python AI and ML\")\n",
    "r = requests.get(url, headers={\"Content-Type\": \"application/json\"})\n",
    "\n",
    "data = r.json()\n",
    "\n",
    "results = data.get('results')\n",
    "\n",
    "results = sorted(results, key=lambda x: x['releaseDate'], reverse=True)\n",
    "ignore_langs = [x.lower() for x in ['German', 'Russian', 'Japanese', 'Chinese', \"Spanish\"]]\n",
    "\n",
    "for idx, result in enumerate(results):\n",
    "    # print(result)\n",
    "    kind = result.get('kind')\n",
    "    if kind != \"podcast-episode\":\n",
    "        continue\n",
    "    releaseDate = result.get('releaseDate')\n",
    "    podcastName = result['collectionName']\n",
    "    title = result['trackName']\n",
    "    pred_lang, is_json = guess_language(title)\n",
    "    lang = None\n",
    "    if is_json:\n",
    "        lang = pred_lang.get(\"language\")\n",
    "    if f\"{lang}\".lower() in ignore_langs:\n",
    "        continue\n",
    "    episodeUrl = result['episodeUrl']\n",
    "    print(idx+1, lang, title, podcastName, releaseDate, episodeUrl)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
