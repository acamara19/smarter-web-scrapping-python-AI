{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install moviepy pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "import pathlib\n",
    "import json\n",
    "from moviepy.editor import VideoFileClip\n",
    "from pydub import AudioSegment\n",
    "from pydub.utils import make_chunks\n",
    "from helpers import utils\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NBS_DIR = pathlib.Path().resolve().parent\n",
    "BASE_DIR = NBS_DIR\n",
    "DATASET_DIR = BASE_DIR / \"dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whisper_model = \"tiny\" # tiny, base, small, medium, large \n",
    "model = whisper.load_model(whisper_model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_audio_chunks(auto_path, chunk_dir=None):\n",
    "    path = pathlib.Path(auto_path).resolve()\n",
    "    if f\"{str(path)}\".endswith('.mp4'):\n",
    "        clip = VideoFileClip(str(path))\n",
    "        audio = clip.audio\n",
    "        path = path.parent / 'audio.mp3'\n",
    "        audio.write_audiofile(str(path))\n",
    "    myaudio = AudioSegment.from_file(str(path))\n",
    "    chunks = make_chunks(myaudio, 30 * 1000) # 30 seconds -> 30_000 ms\n",
    "    #Export all of the individual chunks as wav files\n",
    "    parent = path.parent\n",
    "    if not isinstance(chunk_dir, pathlib.Path): \n",
    "        chunk_dir = parent / \"chunk\"\n",
    "    chunk_dir.mkdir(exist_ok=True)\n",
    "    for current_chunk_path in chunk_dir.glob(\"*.wav\"):\n",
    "        current_chunk_path.unlink()\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        i_padded = f\"{i}\"\n",
    "        if len(i_padded) == 1:\n",
    "            i_padded = f\"0{i}\"\n",
    "        chunk_name = chunk_dir / f\"{i_padded}-chunk.wav\"\n",
    "        chunk.export(str(chunk_name), format=\"wav\")\n",
    "    return len(list(chunk_dir.glob('*.wav')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_language(chunk_path):\n",
    "    audio = whisper.load_audio(str(chunk_path))\n",
    "    audio = whisper.pad_or_trim(audio)\n",
    "    \n",
    "    # make log-Mel spectrogram and move to the same device as the model\n",
    "    if whisper_model == \"large\":\n",
    "        mel = whisper.log_mel_spectrogram(audio=audio, n_mels=128).to(model.device)\n",
    "    else:\n",
    "        mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
    "    \n",
    "    # detect the spoken language\n",
    "    _, probs = model.detect_language(mel)\n",
    "    print(f\"Detected language: {max(probs, key=probs.get)}\")\n",
    "    return max(probs, key=probs.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_chunk_audio_files(max_podcasts=10):\n",
    "    for path in list(DATASET_DIR.glob(\"**/**/podcast.json\"))[:max_podcasts]:\n",
    "        podcast_detail_dir = path.parent\n",
    "        podcasts_dir = podcast_detail_dir.parent\n",
    "        post_dir = podcasts_dir.parent\n",
    "        post_id = post_dir.name\n",
    "        podcast_data = json.loads(path.read_text())\n",
    "        podcast_id = podcast_data.get('trackId')\n",
    "        episode_url = podcast_data.get('episodeUrl')\n",
    "        # print(episode_url, podcast_detail_dir)\n",
    "        episode_url = utils.convert_encoded_url(episode_url)\n",
    "        fname = utils.get_fname(episode_url)\n",
    "        if fname is None:\n",
    "            continue\n",
    "        fpath = podcast_detail_dir / fname\n",
    "        if not fpath.exists():\n",
    "            print(\"Downloading\", fname)\n",
    "            fname = utils.download_file(episode_url, destination_path=podcast_detail_dir)\n",
    "            print('Download complete')\n",
    "        print('Chunking', fname)\n",
    "        chunk_dir = podcast_detail_dir / \"chunk\"\n",
    "        total_chunks = 0\n",
    "        try:\n",
    "            total_chunks = make_audio_chunks(fpath, chunk_dir=chunk_dir)\n",
    "        except:\n",
    "            pass\n",
    "        print('Chunking done with', total_chunks, 'total chunks')\n",
    "        print('Extracting audio language')\n",
    "        lang = \"unknown\"\n",
    "        chunk_list = list(chunk_dir.glob(\"*.wav\"))\n",
    "        if len(chunk_list)>0:\n",
    "            random_chunk = random.choice(chunk_list)\n",
    "            print('Random sample for language detection', pathlib.Path(random_chunk).name)\n",
    "            try:\n",
    "                lang = detect_language(random_chunk)\n",
    "            except:\n",
    "                pass\n",
    "            lang_path = podcast_detail_dir / \"pred-language.txt\"\n",
    "        lang_path.write_text(lang)\n",
    "        print('Predicted audio language is', lang)\n",
    "        print()\n",
    "\n",
    "download_and_chunk_audio_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_chunks(transcribe_all = True, max_podcasts=10):\n",
    "    for path in list(DATASET_DIR.glob(\"**/**/podcast.json\"))[:max_podcasts]:\n",
    "        podcast_detail_dir = path.parent\n",
    "        lang_path = podcast_detail_dir / \"pred-language.txt\"\n",
    "        if not lang_path.exists():\n",
    "            continue\n",
    "        transcript_path = podcast_detail_dir / 'transcript.txt'\n",
    "        if transcript_path.exists() and not transcribe_all:\n",
    "            continue\n",
    "        chunk_dir = podcast_detail_dir / \"chunk\"\n",
    "        files = list(chunk_dir.glob(\"*.wav\"))\n",
    "        sorted_files = sorted(files, key=lambda file: int(file.stem.split('-')[0]))\n",
    "        print('Transcribing', podcast_detail_dir.name)\n",
    "        for chunk_path in sorted_files:\n",
    "            chunk_path = pathlib.Path(chunk_path).resolve()\n",
    "            print('Working on', chunk_path.relative_to(podcast_detail_dir))\n",
    "            result = model.transcribe(str(chunk_path)) \n",
    "            chunk_text_path = chunk_path.parent / f\"{chunk_path.stem}.json\"\n",
    "            chunk_text_path.write_text(json.dumps(result))\n",
    "        print()\n",
    "\n",
    "transcribe_chunks(transcribe_all=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_transcriptions_to_full_transcript():\n",
    "    for path in list(DATASET_DIR.glob(\"**/**/podcast.json\")):\n",
    "        podcast_detail_dir = path.parent\n",
    "        lang_path = podcast_detail_dir / \"pred-language.txt\"\n",
    "        if not lang_path.exists():\n",
    "            continue\n",
    "        chunk_dir = podcast_detail_dir / \"chunk\"\n",
    "        transcript = \"\"\n",
    "        files = list(chunk_dir.glob(\"*.json\"))\n",
    "        sorted_files = sorted(files, key=lambda file: int(file.stem.split('-')[0]))\n",
    "        for result_path in sorted_files:\n",
    "            result_path = pathlib.Path(result_path).resolve()\n",
    "            if not result_path.exists():\n",
    "                continue\n",
    "            try:\n",
    "                result_data = json.loads(result_path.read_text())\n",
    "            except:\n",
    "                result_data = {}\n",
    "            text = result_data.get('text')\n",
    "            if isinstance(text, str):\n",
    "                transcript += f\" {text} \"\n",
    "        transcript_path = podcast_detail_dir / 'transcript.txt'\n",
    "        if transcript != \"\":\n",
    "            transcript_path.write_text(transcript)\n",
    "        print(transcript_path, 'done')\n",
    "\n",
    "chunk_transcriptions_to_full_transcript()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
